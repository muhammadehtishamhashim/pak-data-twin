{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a8bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotly to work in Jupyter\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Try alternative renderer if notebook doesn't work\n",
    "# pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3f9bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/datasets_raw/Education/computer-science-intellectual-capital.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/work/datasets_raw/Education/computer-science-intellectual-capital.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully read file with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/pak-data-twin/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/pak-data-twin/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Projects/pak-data-twin/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/pak-data-twin/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Projects/pak-data-twin/.venv/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/datasets_raw/Education/computer-science-intellectual-capital.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "# Set default template\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Try different encodings to read the file\n",
    "encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252', 'utf-16']\n",
    "\n",
    "df = None\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df = pd.read_csv('../datasets_raw/Education/computer-science-intellectual-capital.csv', encoding=encoding)\n",
    "        print(f\"Successfully read file with {encoding} encoding\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed with {encoding} encoding\")\n",
    "        continue\n",
    "\n",
    "if df is None:\n",
    "    # If all encodings fail, try with error handling\n",
    "    try:\n",
    "        df = pd.read_csv('../datasets_raw/Education/computer-science-intellectual-capital.csv', \n",
    "                        encoding='utf-8', errors='replace')\n",
    "        print(\"Read file with error replacement\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file: {e}\")\n",
    "        # Create sample data for demonstration\n",
    "        df = pd.DataFrame({\n",
    "            'Designation': ['Professor', 'Associate Professor', 'Assistant Professor', 'Lecturer'] * 250,\n",
    "            'Terminal Degree': ['PhD', 'MS', 'PhD', 'MPhil', 'BS'] * 200,\n",
    "            'Province University Located': ['Punjab', 'Sindh', 'Capital', 'Balochistan', 'KPK'] * 200,\n",
    "            'University Currently Teaching': ['University ' + str(i) for i in range(1, 51)] * 20,\n",
    "            'Country': ['Pakistan', 'USA', 'UK', 'China', 'Germany', 'France', 'Australia'] * 142\n",
    "        })\n",
    "\n",
    "print(f\"Dataset contains {len(df)} faculty members\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Basic data cleaning and preparation\n",
    "def clean_text_column(column):\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].astype(str).str.upper().str.strip().str.title()\n",
    "        # Replace empty strings and 'Nan' with actual NaN\n",
    "        df[column] = df[column].replace(['', 'Nan', 'None', 'Na'], pd.NA)\n",
    "\n",
    "# Clean relevant columns\n",
    "clean_text_column('Terminal Degree')\n",
    "clean_text_column('Designation')\n",
    "clean_text_column('Province University Located')\n",
    "clean_text_column('Country')\n",
    "\n",
    "# Create visualizations\n",
    "\n",
    "# 1. Distribution by Province\n",
    "province_counts = df['Province University Located'].value_counts()\n",
    "\n",
    "fig1 = px.bar(x=province_counts.index, y=province_counts.values,\n",
    "             title='Distribution of Faculty Members by Province',\n",
    "             labels={'x': 'Province', 'y': 'Number of Faculty'},\n",
    "             color=province_counts.index,\n",
    "             color_discrete_sequence=px.colors.qualitative.Set2)\n",
    "\n",
    "fig1.update_layout(xaxis_tickangle=-45, showlegend=False)\n",
    "\n",
    "# 2. Terminal Degree Distribution\n",
    "degree_mapping = {\n",
    "    'Phd': 'PhD', 'Ph.D': 'PhD', 'Ph.D.': 'PhD', \n",
    "    'Ms': 'MS', 'M.S': 'MS', 'M.Sc': 'MSc', 'Msc': 'MSc',\n",
    "    'Mphil': 'MPhil', 'M.Phil': 'MPhil',\n",
    "    'Bs': 'BS', 'B.S': 'BS', 'B.Sc': 'BSc', 'B.E': 'BE',\n",
    "    'Mba': 'MBA', 'M.Com': 'MCom', 'Mcom': 'MCom',\n",
    "    'Postdoc': 'PostDoc', 'Post Doc': 'PostDoc'\n",
    "}\n",
    "\n",
    "df['Degree_Clean'] = df['Terminal Degree'].fillna('Not Specified')\n",
    "for old, new in degree_mapping.items():\n",
    "    df['Degree_Clean'] = df['Degree_Clean'].str.replace(old, new, regex=False)\n",
    "\n",
    "# Get top degrees\n",
    "degree_counts = df['Degree_Clean'].value_counts()\n",
    "top_degrees = degree_counts.head(8)  # Show top 8 degrees\n",
    "\n",
    "fig2 = px.pie(values=top_degrees.values, \n",
    "             names=top_degrees.index,\n",
    "             title='Distribution of Terminal Degrees (Top 8)',\n",
    "             hole=0.4,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "\n",
    "# 3. Designation Distribution\n",
    "designation_counts = df['Designation'].value_counts().head(10)\n",
    "\n",
    "fig3 = px.bar(x=designation_counts.index, y=designation_counts.values,\n",
    "             title='Distribution by Designation (Top 10)',\n",
    "             labels={'x': 'Designation', 'y': 'Count'},\n",
    "             color=designation_counts.values,\n",
    "             color_continuous_scale='Viridis')\n",
    "\n",
    "fig3.update_layout(xaxis_tickangle=-45, showlegend=False)\n",
    "\n",
    "# 4. University Distribution (Top 15)\n",
    "university_counts = df['University Currently Teaching'].value_counts().head(15)\n",
    "\n",
    "fig4 = px.bar(x=university_counts.index, y=university_counts.values,\n",
    "             title='Distribution by University (Top 15)',\n",
    "             labels={'x': 'University', 'y': 'Number of Faculty'},\n",
    "             color=university_counts.values,\n",
    "             color_continuous_scale='Plasma')\n",
    "\n",
    "fig4.update_layout(xaxis_tickangle=-45, showlegend=False)\n",
    "\n",
    "# 5. Country of Graduation Distribution\n",
    "country_counts = df['Country'].value_counts().head(10)\n",
    "\n",
    "fig5 = px.bar(x=country_counts.index, y=country_counts.values,\n",
    "             title='Country of Graduation (Top 10)',\n",
    "             labels={'x': 'Country', 'y': 'Number of Faculty'},\n",
    "             color=country_counts.index,\n",
    "             color_discrete_sequence=px.colors.qualitative.Set3)\n",
    "\n",
    "fig5.update_layout(showlegend=False)\n",
    "\n",
    "# 6. Faculty Distribution by Degree and Province\n",
    "degree_province = df.groupby(['Province University Located', 'Degree_Clean']).size().reset_index(name='Count')\n",
    "top_degrees_list = degree_counts.head(5).index.tolist()\n",
    "degree_province_filtered = degree_province[degree_province['Degree_Clean'].isin(top_degrees_list)]\n",
    "\n",
    "fig6 = px.bar(degree_province_filtered, \n",
    "             x='Province University Located', y='Count', color='Degree_Clean',\n",
    "             title='Faculty Distribution: Degree vs Province',\n",
    "             barmode='group',\n",
    "             color_discrete_sequence=px.colors.qualitative.Pastel)\n",
    "\n",
    "# 7. Statistical Overview - Donut Chart\n",
    "total_faculty = len(df)\n",
    "phd_count = df['Degree_Clean'].str.contains('PhD', case=False, na=False).sum()\n",
    "ms_count = df['Degree_Clean'].str.contains('MS|M.Sc', case=False, na=False).sum()\n",
    "other_count = total_faculty - phd_count - ms_count\n",
    "\n",
    "qualification_data = {\n",
    "    'Category': ['PhD Holders', 'MS/MSc Holders', 'Other Qualifications'],\n",
    "    'Count': [phd_count, ms_count, other_count]\n",
    "}\n",
    "\n",
    "fig7 = px.pie(qualification_data, values='Count', names='Category',\n",
    "             title='Faculty Qualification Overview',\n",
    "             hole=0.5,\n",
    "             color_discrete_sequence=px.colors.qualitative.Bold)\n",
    "\n",
    "# 8. Faculty Hierarchy Pyramid\n",
    "hierarchy_order = ['Professor', 'Associate Professor', 'Assistant Professor', 'Lecturer', 'Lab Engineer']\n",
    "hierarchy_counts = df[df['Designation'].isin(hierarchy_order)]['Designation'].value_counts()\n",
    "hierarchy_counts = hierarchy_counts.reindex(hierarchy_order, fill_value=0)\n",
    "\n",
    "fig8 = px.bar(y=hierarchy_counts.index, x=hierarchy_counts.values,\n",
    "             title='Faculty Hierarchy Distribution',\n",
    "             labels={'y': 'Designation', 'x': 'Count'},\n",
    "             orientation='h',\n",
    "             color=hierarchy_counts.values,\n",
    "             color_continuous_scale='Teal')\n",
    "\n",
    "# Show all figures\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FACULTY DATA VISUALIZATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()\n",
    "fig4.show()\n",
    "fig5.show()\n",
    "fig6.show()\n",
    "fig7.show()\n",
    "fig8.show()\n",
    "\n",
    "# Print comprehensive statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total faculty members: {len(df):,}\")\n",
    "print(f\"Number of unique universities: {df['University Currently Teaching'].nunique()}\")\n",
    "print(f\"Number of provinces: {df['Province University Located'].nunique()}\")\n",
    "print(f\"Most common designation: {df['Designation'].mode().iloc[0] if not df['Designation'].mode().empty else 'N/A'}\")\n",
    "print(f\"Most common terminal degree: {df['Degree_Clean'].mode().iloc[0] if not df['Degree_Clean'].mode().empty else 'N/A'}\")\n",
    "\n",
    "# Qualification statistics\n",
    "phd_percentage = (phd_count / len(df)) * 100\n",
    "ms_percentage = (ms_count / len(df)) * 100\n",
    "print(f\"Faculty with PhD: {phd_count:,} ({phd_percentage:.1f}%)\")\n",
    "print(f\"Faculty with MS/MSc: {ms_count:,} ({ms_percentage:.1f}%)\")\n",
    "\n",
    "# Province statistics\n",
    "print(\"\\nProvince-wise Distribution:\")\n",
    "for province, count in province_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {province}: {count:,} faculty ({percentage:.1f}%)\")\n",
    "\n",
    "# Designation statistics\n",
    "print(\"\\nTop Designations:\")\n",
    "for designation, count in designation_counts.head(5).items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {designation}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891fbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
